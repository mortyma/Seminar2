\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}

\usepackage{comment}
\usepackage{hyperref}
%page boarders
\usepackage[vmargin=3cm, hmargin=3cm]{geometry}
\usepackage{float}
\floatstyle{plaintop}
\usepackage{paralist} %compactitem
\usepackage{fixltx2e} %some latex fixes
\usepackage{microtype} %Subliminal refinements towards typographical perfection
\setlength{\emergencystretch}{2em}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathrsfs} %Support use of the Raph Smith’s Formal Script font in mathematics
\usepackage[sc]{mathpazo} %mathematical fonts
\usepackage{amsfonts}
\usepackage{booktabs}
\usepackage[margin=10pt, font=small, labelfont=bf]{caption}

\usepackage{color}
\newcommand\todo[1]{\textcolor{red}{(#1)}}

\begin{document}

\title{The Power of Two Random Choices\\ 
\large A follow up seminar to the Parallel Algorithms lecture\footnote{Jesper Larsson Träff, lecture ``Parallel Algorithms'', 2012 winter term at TU Wien.}}
\author{Martin Kalany, 0825673}

\maketitle
\begin{abstract}

\end{abstract}


\section{Introduction}
\label{sec:intro}
Suppose that $m$ balls are thrown into $n$ bins, according to some strategy. We are interested in the \emph{number of balls in the fullest bin}, also called the \emph{maximum load}. Equivalently, one can look at the \emph{addative gap} of the allocation, that is the difference of the number of balls in the fullest bin and the average amount of balls in the bins. These \emph{balls-into-bins games} or \emph{allocation problems} have been studied extensively in the probability literature (see e.g., \cite{JK77}). In the context of Computer Science, the balls-into-bins model is useful to study e.g., strategies for distributing \emph{tasks} (balls) to \emph{processors} (bins) as evenly as possible without having to query all processors for the number of tasks currently assigned to them.

A simple strategy for the balls-into-bins problem is to choose one bin uniformly and independently at random for each ball, which we will call the \emph{single-choice balls-into-bins} strategy. Using this strategy, the maximum load of the fullest bin will be $\frac{m}{n} + \Theta\left(\sqrt{\frac{m \log n}{n}}\right)$ with high probability\footnote{We say that an event $\mathcal E$ occurs \emph{with high probability} (w.h.p.) if $\Pr\left[\mathcal E \right] = 1 - o(1)$, except when stated otherwise.}~\cite{RS98}.

Consider a variation of the above \emph{single-choice balls-into-bins} strategy: For each ball, chose $d \geq 2$ bins independently and uniformly at random and place the ball into the \emph{least full bin}\footnote{If there are multiple bins with the same minimal load, chose one among them arbitrarily.}. This simple \emph{multiple-choice balls-into-bins} scheme, which we will call the \emph{Greedy} algorithm, achieves a maximum load of $\frac{m}{n} + \Theta\left(\frac{\log \log n}{\log d}\right)$ w.h.p.~\cite{ABKU99}~\cite{BCSV06}. This apparently minor change introduces a small amount of choice which, compared to the single-choice scheme, leads to a significant reduction in the maximum load. 
\begin{comment}
Curiously, the exponential decrease in the gap is already achieved having just two choices (that is, $d=2$). Each additional choice decreases the bound for the maximum gap by just a constant factor~\cite{MRS01}. 
\end{comment}
Extensive research following the influental paper by Azar et. al \cite{ABKU99}, who were the first to explicitly prove this phenomenon, suggests that this \emph{two-choice paradigm} is not just an artificat of the simple balls-into-bins model, but a general principle applicable to a variety of problems. 

Condsider a slightly more involved strategy, which we will call the \emph{Always-go-left} scheme: Suppose that the $n$ bins are partitioned evenly into $d$ groups, each of size $\lfloor \frac{n}{d}\rfloor$ or $\lceil\frac{n}{d}\rceil$ \todo{simplify to n/d?}. We select one bin from each group uniformly and independently at random and put the ball into the least full of those $d$ bins. In case a tie occurs, put the ball into the \emph{left-most} bin. That is, assuming a fixed ordering of bins $b_i$ for $1 \leq i \leq n$, from among the $d' \leq d$ bins with same minimal load, we put the ball into the bin with smallest index $i$. Somewhat surprisingly, V\"ocking \cite{VOC03} showed that such a strategy employing \emph{asymetric tie-breaking} in combination with \emph{partitioning}\todo{check} reduces the bound for the gap to $\Theta \left( \frac{\log\log n}{d \log \Phi_d}\right)$ \todo{$\Phi_d$ is undefined}.

The paper is organized as follows: We will first introduce different variations of the \emph{balls-into-bins problem} in Section \ref{sec:classification} to provide some overview of different directions in research as well as possibilities of abstraction from applications, some of which are listed in Section \ref{sec:applications}. Sections \ref{sec:single-choice} to \ref{sec:multiple-choice} will deal with the most basic variation of the balls-into-bins problem, namely the sequential, finite and static variant (see Section \ref{sec:classification} for details). For comparison and as a starting point, Section \ref{sec:single-choice} provides the results for the single-choice balls-into-bins problem. \todo{TODO: multiple-choice, analysis, mention that witness tree method very helpful}  See also \cite{MRS01} an overview of proof techniques for the given problem.  

\begin{comment}
In Section \ref{sec:strategies}, we will provide asymptotic bounds for the addative gap of this strategy, which we will then use to devise more complex strategies that significantly reduce these bounds. 
\end{comment}

\begin{comment}
These result may sometimes seem surprising, which is why we will denote a significant part of this article to demonstrate proofs in detail. This proof technique may be useful for devising asymptotic bounds for the additive gap of different balls-into-bins scenarios and strategies.
\end{comment}


\section{Classification}
\label{sec:classification}
Several different variations of this problem exist, which may be classified by the following properties:
\begin{compactitem}
\item In a \emph{sequential process}, the balls arrive one after another. A  ball is dealt with only after the previous ball has been placed. Contrary, in a \emph{parallel process}, balls arrive in sets and the balls in one set are dealt with simultaneously \cite{ABS98}. 
\item In a \emph{static problem}, the balls are placed into the bins and no balls are ever removed. In a \emph{dynamic problem}, balls can also be removed from the system. In a simple \emph{random deletions} model, for each newly inserted ball a ball choosen uniformly and independently at random from among the balls currently in the bins is removed from the system \cite{ABKU99} \cite{MRS01}. More elaborate shemes exists: An \emph{oblivious adversery} specifies the sequence of insertions and deletions of balls in advance, without any knowledge of the placement of the balls \cite{CFM+98}. Another approach was studied by Adler et. al \cite{ABS98} in the context of the parallel balls-into-bins problem: In each bin, the balls are stored in FIFO-order and at every time step the first ball in each of the bins is deleted. 
\item A \emph{finite process} is analyzed for a given time interval that is known beforehand, whereas for an \emph{infinite process}, a placement and a deletion process is defined over an infinite time span \cite{ABS98}.
\end{compactitem}


We will distinguish two cases with respect to the number of balls $m$. In the \emph{lightly loaded case}, $m$ is in the order of $n$, whereas in the \emph{heavily loaded case}, $m$ is aribtrarily large. For clarity, we will assume that $m = n$ in the slightly loaded case and that $m \ll n$\todo{TODO} \footnote{Let $f$, $g$ be arbitrary functions. Then, $f \ll g$ means $f = o(g)$ and $ f \gg g$ means $f = \omega(g)$} in the heavily loaded case. 

\section{Applications}
\label{sec:applications}
The two-choice paradigm applied to the balls-into-bins model has several useful applications, some of which we will outline here. The applications in \emph{Hashing} (Section \ref{sec:hashing}), \emph{Online Load Balancing} (Section \ref{sec:loadbalancing}) and \emph{Emulation of shared memory machines on distributed memory machines} \ref{sec:DMM}) share a close relation to load balancing. Section \ref{sec:circuitrouting} applies the balls-into-bins model and the two-choice paradigm in a different context, namely that of routing circuits in multi-stage interconnection networks with minimal congestion.

\subsection{Hashing}
\label{sec:hashing}
A simple hash table implementation typically uses a single hash function to map elements to entries in a table. If more than one element is mapped to the same entry, all elements mapped to this table entry are stored in a \emph{chain}, usually implemented as a linked list. The maximum time to search for an element is then proportional to the length of the longest chain in the hash table. 

It is easy to see how the balls-into-bins idea can be applied: Assuming a perfect hash function\footnote{i.e., each of the $n$ elements is mapped to one of the $n$ table entries uniformly and independently at random}, the elements are balls to be mapped to table entries or bins, implying a worst case look-up time of $\Theta\left(\frac{\log n}{\log \log n}\right)$ w.h.p. Applying the two-choice paradigm by using two hash functions and mapping elements to the least full of two table entries implies a bound of $\Theta\left(\log \log n\right)$ w.h.p. This approach is easy to parallelize, it does not require re-hashing of data and requires only two hash functions \cite{ABKU99} \cite{MRS01}.

\subsection{Online load balancing}
\label{sec:loadbalancing}
The following simple scenario is a typical application of online load balancing: Consider $n$ servers\footnote{Such as file-, database- or network servers} and $m$ requests issued by clients that need to be handled by these servers. For simplicity, assume that each task can be handled by any server and that all tasks are of the same size, i.e., require the same amount of execution time.

To maximize the throughput of the servers, a uniform distribution of tasks to servers is desireable. This can easily be achieved by a central dispatcher. However, such a central dispatcher poses a bottleneck within a distributed system and querying $m$ servers for their current load involves significant overhead, e.g., sending a message to each server and waiting for the reply and more efficient solutions are neccessary. As with hashing, the balls-into-bins model can be applied easily: we need to assign tasks (the balls) to servers (the bins). Assuming tasks are assigned to servers uniformly and independently at random, the two-choice paradigm is directly applicable: If each client samples two random servers for their load and sends issues its request to the least loaded server, the overhead is comperatively small and the difference in load on the $n$ servers is bounded by $\Theta\left(\log \log n\right)$ w.h.p. \cite{KLM92} \cite{RS98} \cite{MRS01}.  

\subsection{Emulation of shared memory machines on distributed memory machines}
\label{sec:DMM}
The \emph{Parallel Random Access Machine} model\footnote{as defined in the lecture or in~\cite{P03}}, or \emph{PRAM} for short, is a high level abstraction of a shared memory machine, in which memory access by any processor to any memory location is assumed to require constant time. It is especially useful for the study of parallel algorithms. However, a PRAM is much harder to realize in hardware than a \emph{Distributed Memory Machine} (DMM). Thus, ways to emulate a PRAM on a DMM have been studied extensivly. Such an emulation distributes the processors and memory cells of the PRAM to the processors and memory modules (typically one per processor) of the DMM with the goal to reduce the slowdown of the emulation, which is the time the DMM requires to simulate one step of the PRAM. Each memory modul can handle only one memory access at a time step. More accesses to the same module will result in memory contention. The balls-into-bins idea is useful for managing communication between the processors and the memory modules such that memory contention is minimal. For details, see Karp et. al \cite{KLM92} and the papers referenced there. 
 
\subsection{Low congestion circuit routing}
\label{sec:circuitrouting}
In multi-stage interconnection networks, virtual circuit-switching is used to route communication. For simplicity, we consider the \emph{permutation routing problem}, where one request originates at each of the $n$ input nodes and one request is destined for each of the $n$ output nodes and assume a \emph{butterfly network} as the underlying interconnection network (see \cite{CLR09} for a detailed definition). Then, congestions is the maximum number of paths that are routed through a network link. The goal of a \emph{circuit routing algorithm} is to to allocate paths for all $n$ communication requests such that congestion is minimal.

In this context, \emph{Valiant's paradigm} \cite{V82} states that any such permutation routing problem can be solved by transforming it into two problems: First, find a path for each request to an intermediate destination chosen uniformly and independently at random. Next, find a path from the intermediate to the actual destination. This routing technique is analogous to the single-choice balls-into-bins problem where each communication request (or ball) chooses an intermediate destination (a bin) at random. In this analogy, the congestion achieved by Valiant's paradigm corresponds to the maximum load in the balls-into-bins model, thus implying a bound of $\Theta\left(\log \log n\right)$ on the congestion w.h.p. \cite{CMM+98} \cite{MRS01}. 

Applying the two-choice paradigm in this context is somewhat more involved and beyond the scope of this paper. The interested reader may find more details in \cite{CMM+98}.

\section{Single-choice balls-into-bins}
\label{sec:single-choice}
We will now consider the most basic variant of the balls-into-bins problem: Namely the static, finite and sequential variant. Thus, the balls are assumed to arrive sequentially, no strategy for deleting balls in the bins has to be considered and we are interested in a bound for the maximum load or gap only after all $m$ balls have arrived. 

In the \emph{single-choice balls-into-bins} strategy, each ball is placed into a bin chosen uniformly and independently at random. In other words, a ball gets placed into a certain bin with probability $\frac{1}{n}$.

The fullest bin contains
\[
\Theta \left( \frac{\log n}{\log \log n} \right)
\] 
balls in the lightly loaded case w.h.p. Since the average load of the bins is 1, this is also a bound for the gap. 
%More accurately, the number of balls in the bin with the most balls is $\Gamma^{-1}\left(n\right)\left(1+O\left(\frac{1}{\log \Gamma^{-1}\left(n\right)}\right)\right)$ \cite{G91}. %\todo{really include Gonnet?}
In the \emph{heavily loaded case} the maximum load is 
\[
\frac{m}{n} + \Theta\left(\sqrt{\frac{m \log n}{n}}\right)
\] 
w.h.p.~\cite{RS98}.

\section{Multiple-choice balls-into-bins}
\label{sec:multiple-choice}
The \emph{single-choice balls-into-bins strategy} (Section \ref{sec:single-choice}) chooses one bin uniformly and independently at random for each ball. A \emph{multiple-choice balls-into-bins strategy} generalizes this idea by  choosing $d \geq 2$ bins and placing the ball into the least full bin. Depending on how the $d$ locations are sampled, we distinguish three classes of placement algorithms \cite{VOC03}. 

Thus, let $B$ be the set of bins $\{1,2...n\}$, $\Omega = B^{d}$ be the sample space and $\mathcal{F} = 2^{\Omega}$ be the set of measurable events. We are only interested in events that represent a set of bins of size $d$. Thus, let $\mathcal{F}_d = \{\mathcal{E} \in \mathcal{F}: \left\vert \mathcal{E} \right\vert = d\}$ and set $\Pr\left(\mathcal{E}  \right) = 0$  $\forall \mathcal{E} \in \mathcal{F} \setminus \mathcal{F}_d $. The three classes of algorithms are distinguished by the probability function $\Pr\left(\mathcal{E}\right)$ for events $\mathcal{E} \in \mathcal{F}_d$:
\begin{itemize}
\item  \emph{Uniform and independent.} Choose each of the $d$ bins for a ball uniformly and independently at random from the set of bins $B$. This implies 
\[
\forall \mathcal{E} \in \mathcal{F}_d: \Pr\left(\mathcal{E}\right) = \frac{1}{n ^{d}}
\]
\item Class 2: \emph{Non-uniform and independent.} Choose the $i$th bin from $B$ independently at random according to some probability function
\[
\Pr: B \rightarrow \left[0,1\right]
\]

\item Class 3: \emph{Non-uniform and dependent.} Choose the $d$ bins for a ball from $\Omega$ at random:
\[
\Pr: B^{d} \rightarrow \left[0,1\right]
\]

\end{itemize} 
 

We will discuss two different multiple-choice placement strategies: The \emph{Greedy} algorithm (Section \ref{sec:greedy}) belongs to class 1, whereas the \emph{Always-Go-Left} scheme (Section \ref{sec:AlwaysGoLeft}) uses a non-uniform and independent selection of $d$ bins and thus belongs to class 2.

\subsection{The Greedy scheme}
\label{sec:greedy}

Consider a variation of the above \emph{one-choice balls-into-bins} strategy, which we will call the \emph{Greedy scheme}: For each ball, choose $d \geq 2$ bins independently and uniformly at random and place the ball into the \emph{least full bin}. If there are multiple bins with the same minimal load, chose one among them arbitrarily. Note that the $d$ selected bins are not necessarily distinct. 

The \emph{Greedy scheme} achieves a maximum load of 
\[
\frac{m}{n} + \Theta\left(\frac{\log \log n}{\log d} \right)
\]
for all $m$ w.h.p. \cite{ABKU99} \cite{BCSV06}.

This implies a gap of $\Theta\left(\log \log n \right)$ for arbitrarily large $m$, which is remarkable in several ways:
\begin{compactitem}
\item The apparently small change made for the \emph{Greedy} algorithm compared to the \emph{single-choice balls-into-bins} scheme results in an exponential decrease of the gap, even for $d=2$. 
\item Each additional choice ($d > 2$) decreases the gap by only a constant factor \cite{MRS01}. 
\item For the \emph{heavily loaded case}, the resulting gap of the \emph{multiple-choice balls-into-bins} strategy does not depend on the number of balls $m$. In contrast, the bound for the \emph{one-choice balls-into-bins} scheme diverges with $m$.
\begin{comment}
\todo{the following is only true for class 1 algorithms}
\item The given bounds are \emph{tight}, meaning that no other strategy that places each ball into one of $d$ randomly selected bins achieves a gap that is asymptotically lower.
\end{comment}
\end{compactitem}

We will provide a detailed proof of this property in Section \ref{sec:analysis}.

\subsubsection{History}
\label{sec:historyOfGreedy}
The history of proving this remarkable property of the two-choice paradigm is in itself quite interesting. It was first proven by Azar et al. \cite{ABKU99} for the case $m = n$. In the same paper, they claimed that the bound holds for arbitrary $m$. Unfortunately, their analysis breaks down for the heavily loaded case, where $m = \omega\left(n\right)$. Berenbrink at. all \cite{BFZR08} were the first to proof that indeed the same bound holds for the heavily loaded case\footnote{However, they use a slightly different definition for w.h.p.: An event $\mathcal E$ occurs with high probability if $\Pr\left[\mathcal E \right]  \geq 1- n^{-\alpha}$, for an arbitrarily chosen constant $\alpha \geq 1$.}. A simplified proof may be found in \cite{TW13}. Curiously, the case $d = 2$ was implicitly proven by Karp et al. in the context of simulating PRAMs on distributed memory machines\cite{KLM92}. As we will see in the next section, V\"ocking was able to slightly improve the bound as well as to show that the always-go-left strategy that he introduces is optimal up to additive constants \cite{VOC03}.


\subsection{The Always-Go-Left scheme}
\label{sec:AlwaysGoLeft}
The multiple-choice balls-into-bins strategy presented in Section \ref{sec:multiple-choice} assumes that $d$ bins are chosen uniformly and independently at random. V\"ocking \cite{VOC03} was the first to study the impact of non-uniform and dependent selections of the $d$ bins. Surprisingly, a multiple-choice balls-into-bins strategy with a \emph{nonuniform and independent} selection of the $d$ bins, such as the \emph{Always-Go-Left} algorithm introduced in \cite{VOC03}, achieves better\cite{BCSV06} load balancing than the \emph{Greedy} scheme (Section \ref{sec:greedy}). Furthermore, V\"ocking proved that the \emph{Always-Go-Left} algorithm is almost optimal \todo{be more precise}.

\todo{algorithm}

\subsection{Analysis}
\label{sec:analysis}

\subsubsection{Preliminaries}
\label{sec:preliminaries}
\todo{where to put this? required for  bound of always-go-left in intro}
We define $d$-ary Fibonacci numbers as follows. For $k \leq0$, $F_d(k) = 0$, $F_d(1) = 1$ and for $k \geq 1$,

\[
F_d(k) = \sum_{i=1}^{d}F_d(k-i)
\]
Furthermore, define 
\[
\Phi_d = \lim_{k \rightarrow \infty} \sqrt[k]{F_d(k)}
\]
Notice that $F_2$ corresponds to the usual Fibonacci numbers, while $\Phi_2 $ corresponds to the golden ratio \cite{Knuth73}, which is generalized to $\Phi_d$, for which 
\[
i, j \in \mathbb{N}, i < j \Rightarrow \Phi_i < \Phi_j
\]
and 
\[
\lim_{d\rightarrow \infty} \Phi_d = 2
\]
hold.

\section{Conclusion}
\label{sec:conclusion}

%bibliography
\bibliographystyle{acm}
\bibliography{../sources} 
\end{document}
